{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOZDn0enVxR3ieLvxVVqKj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubham2007-pro/5CS037/blob/main/Workshop5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ofQYGatqNQdd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw4d_plWNWFl",
        "outputId": "ec93a6d3-848f-4c27-a3b7-268d2b836c34"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f11e87b2",
        "outputId": "9832f242-b249-44f5-e26a-d1c6b914df75"
      },
      "source": [
        "\n",
        "# Load the dataset and inspect its structure\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/student.csv\")\n",
        "\n",
        "# Display first 5 rows to understand structure\n",
        "print(\"Top 5 rows:\")\n",
        "print(data.head())\n",
        "\n",
        "# Display last 5 rows\n",
        "print(\"\\nBottom 5 rows:\")\n",
        "print(data.tail())\n",
        "\n",
        "# Display dataset information (columns, datatype, null values)\n",
        "print(\"\\nDataset Information:\")\n",
        "print(data.info())\n",
        "\n",
        "# Display statistical summary (mean, std, min, max)\n",
        "print(\"\\nDescriptive Statistics:\")\n",
        "print(data.describe())\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 rows:\n",
            "   Math  Reading  Writing\n",
            "0    48       68       63\n",
            "1    62       81       72\n",
            "2    79       80       78\n",
            "3    76       83       79\n",
            "4    59       64       62\n",
            "\n",
            "Bottom 5 rows:\n",
            "     Math  Reading  Writing\n",
            "995    72       74       70\n",
            "996    73       86       90\n",
            "997    89       87       94\n",
            "998    83       82       78\n",
            "999    66       66       72\n",
            "\n",
            "Dataset Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype\n",
            "---  ------   --------------  -----\n",
            " 0   Math     1000 non-null   int64\n",
            " 1   Reading  1000 non-null   int64\n",
            " 2   Writing  1000 non-null   int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 23.6 KB\n",
            "None\n",
            "\n",
            "Descriptive Statistics:\n",
            "              Math      Reading      Writing\n",
            "count  1000.000000  1000.000000  1000.000000\n",
            "mean     67.290000    69.872000    68.616000\n",
            "std      15.085008    14.657027    15.241287\n",
            "min      13.000000    19.000000    14.000000\n",
            "25%      58.000000    60.750000    58.000000\n",
            "50%      68.000000    70.000000    69.500000\n",
            "75%      78.000000    81.000000    79.000000\n",
            "max     100.000000   100.000000   100.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.drop(columns=['Writing']).values\n",
        "Y=df['Writing'].values"
      ],
      "metadata": {
        "id": "5XW0I3u2N5xR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(x,y,test_size=0.2,random_seed=42):\n",
        "  np.random.seed(random_seed)\n",
        "  indices=np.arange(x.shape[0])\n",
        "  np.random.shuffle(indices)\n",
        "  test_split_size=int(len(x)*test_size)\n",
        "  test_indices=indices[:test_split_size]\n",
        "  train_indices=indices[test_split_size:]\n",
        "  x_train=x[train_indices]\n",
        "  x_test=x[test_indices]\n",
        "  y_train=y[train_indices]\n",
        "  y_test=y[test_indices]\n",
        "  return x_train,x_test,y_train,y_test"
      ],
      "metadata": {
        "id": "TryUJgOsOI0Q"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#Define the cost function\n",
        "def cost_function(X, Y, W):\n",
        "  \"\"\" Parameters:\n",
        "  This function finds the Mean Square Error.\n",
        "  Input parameters:\n",
        "  X: Feature Matrix\n",
        "  Y: Target Matrix\n",
        "  W: Weight Matrix\n",
        "  Output Parameters:\n",
        "  cost: accumulated mean square error.\n",
        "  \"\"\"\n",
        "  m=len(Y)\n",
        "  y_pred=np.dot(X,W)\n",
        "  cost=(1/(2*m))*np.sum(np.square(y_pred-Y))\n",
        "  return cost"
      ],
      "metadata": {
        "id": "BJrIJATbOMBz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x=np.array([[1,2],[3,4],[5,6]])\n",
        "# y=np.array([3,7,11])\n",
        "# w=np.array([1,1])\n",
        "# print(cost_function(x,y,w))"
      ],
      "metadata": {
        "id": "uEmJQvDcOiFA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, Y, W, alpha, iterations):\n",
        "  \"\"\"\n",
        "  Perform gradient descent to optimize the parameters of a linear regression model.\n",
        "  Parameters:\n",
        "  X (numpy.ndarray): Feature matrix (m x n).\n",
        "  Y (numpy.ndarray): Target vector (m x 1).\n",
        "  W (numpy.ndarray): Initial guess for parameters (n x 1).\n",
        "  alpha (float): Learning rate.\n",
        "  iterations (int): Number of iterations for gradient descent.\n",
        "  Returns:\n",
        "  tuple: A tuple containing the final optimized parameters (W_update) and the history of cost values\n",
        "  .\n",
        "  W_update (numpy.ndarray): Updated parameters (n x 1).\n",
        "  cost_history (list): History of cost values over iterations.\n",
        "  \"\"\"\n",
        "  # Initialize cost history\n",
        "  cost_history = [0] * iterations\n",
        "  # Number of samples\n",
        "  m = len(Y)\n",
        "  for iteration in range(iterations):\n",
        "  # Step 1: Hypothesis Values\n",
        "    Y_pred = np.dot(X, W)\n",
        "  # Step 2: Difference between Hypothesis and Actual Y\n",
        "    loss = Y_pred - Y\n",
        "  # Step 3: Gradient Calculation\n",
        "    dw =(1/m)*np.dot(X.T,loss)\n",
        "  # Step 4: Updating Values of W using Gradient\n",
        "    W_update = W - alpha * dw\n",
        "    W=W_update\n",
        "  # Step 5: New Cost Value\n",
        "    cost = cost_function(X, Y, W_update)\n",
        "    cost_history[iteration] = cost\n",
        "  return W_update, cost_history"
      ],
      "metadata": {
        "id": "xeiTAHqwOk-2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Generate random test data\n",
        "# np.random.seed(0) # For reproducibility\n",
        "# X = np.random.rand(100, 3) # 100 samples, 3 features\n",
        "# Y = np.random.rand(100)\n",
        "# W = np.random.rand(3) # Initial guess for parameters\n",
        "# # Set hyperparameters\n",
        "# alpha = 0.01\n",
        "# iterations = 1000\n",
        "# # Test the gradient_descent function\n",
        "# final_params, cost_history = gradient_descent(X, Y, W, alpha, iterations)\n",
        "# # Print the final parameters and cost history\n",
        "# print(\"Final Parameters:\", final_params)\n",
        "# print(\"Cost History:\", cost_history)"
      ],
      "metadata": {
        "id": "B7CFRF9sOn-2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation - RMSE\n",
        "def rmse(Y, Y_pred):\n",
        "  \"\"\"\n",
        "  This Function calculates the Root Mean Squres.\n",
        "  Input Arguments:\n",
        "  Y: Array of actual(Target) Dependent Varaibles.\n",
        "  Y_pred: Array of predeicted Dependent Varaibles.\n",
        "  Output Arguments:\n",
        "  rmse: Root Mean Square.\n",
        "  \"\"\"\n",
        "  m=len(Y)\n",
        "  rmse = np.sqrt(1/m*np.sum(np.square(Y-Y_pred)))\n",
        "  return rmse"
      ],
      "metadata": {
        "id": "TjZb-qeUOqHO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation - R2\n",
        "def r2(Y, Y_pred):\n",
        "  \"\"\"\n",
        "  This Function calculates the R Squared Error.\n",
        "  Input Arguments:\n",
        "  Y: Array of actual(Target) Dependent Varaibles.\n",
        "  Y_pred: Array of predeicted Dependent Varaibles.\n",
        "  Output Arguments:\n",
        "  rsquared: R Squared Error.\n",
        "  \"\"\"\n",
        "  mean_y = np.mean(Y)\n",
        "  ss_tot = np.sum(np.square(Y - mean_y))\n",
        "  ss_res = np.sum(np.square(Y - Y_pred))\n",
        "  r2 = 1-ss_res/ss_tot\n",
        "  return r2"
      ],
      "metadata": {
        "id": "YdzDkit2OsYY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "def main():\n",
        "  # Step 1: Load the dataset\n",
        "  data = df\n",
        "  # Step 2: Split the data into features (X) and target (Y)\n",
        "  X = data[['Math', 'Reading']].values # Features: Math and Reading marks\n",
        "  Y = data['Writing'].values # Target: Writing marks\n",
        "  # Step 3: Split the data into training and test sets (80% train, 20% test)\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
        "  # Step 4: Initialize weights (W) to zeros, learning rate and number of iterations\n",
        "  W = np.zeros(X_train.shape[1]) # Initialize weights\n",
        "  alpha = 0.00001 # Learning rate\n",
        "  iterations = 1000 # Number of iterations for gradient descent\n",
        "  # Step 5: Perform Gradient Descent\n",
        "  W_optimal, cost_history = gradient_descent(X_train, Y_train, W, alpha, iterations)\n",
        "  # Step 6: Make predictions on the test set\n",
        "  Y_pred = np.dot(X_test, W_optimal)\n",
        "  # Step 7: Evaluate the model using RMSE and R-Squared\n",
        "  Y_train_pred = np.dot(X_train, W_optimal)\n",
        "  train_rmse = rmse(Y_train, Y_train_pred)\n",
        "  train_r2 = r2(Y_train, Y_train_pred)\n",
        "  model_rmse = rmse(Y_test, Y_pred)\n",
        "  model_r2 = r2(Y_test, Y_pred)\n",
        "  # Step 8: Output the results\n",
        "  print(\"Final Weights:\", W_optimal)\n",
        "  print(\"Cost History (First 10 iterations):\", cost_history[:10])\n",
        "  print(\"RMSE on Training Set:\", train_rmse)\n",
        "  print(\"R-Squared on Training Set:\", train_r2)\n",
        "  print(\"RMSE on Test Set:\", model_rmse)\n",
        "  print(\"R-Squared on Test Set:\", model_r2)\n",
        "  # Execute the main function\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0sEi4r6OwVz",
        "outputId": "48c6be39-960b-4259-fbfe-eee1ee244ac2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Weights: [0.34811659 0.64614558]\n",
            "Cost History (First 10 iterations): [np.float64(2013.165570783755), np.float64(1640.286832599692), np.float64(1337.0619994901588), np.float64(1090.4794892850578), np.float64(889.9583270083234), np.float64(726.8940993009545), np.float64(594.2897260808594), np.float64(486.4552052951635), np.float64(398.7634463599484), np.float64(327.4517147324688)]\n",
            "RMSE on Training Set: 5.128473455543203\n",
            "R-Squared on Training Set: 0.8843826546696121\n",
            "RMSE on Test Set: 5.2798239764188635\n",
            "R-Squared on Test Set: 0.8886354462786421\n"
          ]
        }
      ]
    }
  ]
}